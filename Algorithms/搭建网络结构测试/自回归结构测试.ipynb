{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993ba582",
   "metadata": {},
   "source": [
    "### 测试目标：\n",
    "\n",
    "- 构建一个可泛化的随意构建自回归结构的actor\n",
    "- actor由多个自回归块和末端动作网络组成\n",
    "- 自回归块是单维离散动作分布，末端动作网络使用无共享backbone的多头网络结构，使用单维Cat、Cont和Bern构成\n",
    "- 所有自回归结构在wrapper里面构建\n",
    "- 未设计GRU或自注意力结构\n",
    "\n",
    "\n",
    "关键设计点总结：\n",
    "1. Wrapper 全权负责拓扑结构：\n",
    "   - __init__ 中通过循环计算 current_input_dim += action_dim，实现了自动的维度对齐。你不需要手动计算第 3 层输入的维度是 69 还是 70。\n",
    "2. Teacher Forcing 实现：\n",
    "   - 在 evaluate_actions 中，代码使用 gt_idx (Ground Truth) 生成 One-Hot 向量拼接到 curr_input。这保证了在训练时，后续节点的梯度能正确传导回前面的节点（如果前面的节点输出也是可导的——但在 PPO 中我们通常只对 Logits 求导，这里主要是为了条件概率计算的准确性：$P(B|A_{true})$）。\n",
    "3. 高度模块化：\n",
    "    - layers 是一个 nn.ModuleList。\n",
    "    - 每一层都是一个独立的 MLP（来自 MLP_heads）。\n",
    "    - 没有共享的主干网络（Backbone）。在级联结构中，这通常更好，因为每个决策阶段关注的特征可能完全不同。如果需要共享特征，可以在 Wrapper 最开始加一个 Feature Extractor，然后把提取的特征作为 state 传入循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2d4934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\3_Machine_Learning_in_Python\\project03_fire_and_dodge_missile\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "def get_current_file_dir():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return os.getcwd()\n",
    "        else:\n",
    "            return os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        return os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "cur_dir = get_current_file_dir()\n",
    "project_root = os.path.dirname(os.path.dirname(cur_dir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print(project_root)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical, Bernoulli, Normal\n",
    "import numpy as np\n",
    "\n",
    "# 假设 MLP_heads 在同级目录下，如果不是请调整 import\n",
    "from Algorithms.MLP_heads import PolicyNetDiscrete, PolicyNetContinuous, PolicyNetBernouli, PolicyNetMultiDiscrete\n",
    "from Algorithms.Utils import SquashedNormal # 假设 Utils 也在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f2d647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Cascade Actor with State Dim: 50\n",
      "  [Layer 0] target_sel (Cat): In=50, Out=5 -> Next In=55\n",
      "  [Layer 1] maneuver (Cat): In=55, Out=14 -> Next In=69\n",
      "  [Layer 2] execution (Tail-Bern): In=69, Out=1\n",
      "  [Layer 2] execution (Tail-Cont): In=69, Out=2\n",
      "  [Layer 2] execution (Tail-Cat): In=69, Out=[2, 2]\n",
      "\n",
      "--- Network Constructed ---\n",
      "\n",
      "--- Testing Get Action (Inference) ---\n",
      "Action 'target_sel': Shape (4,)\n",
      "Action 'maneuver': Shape (4,)\n",
      "Action 'execution_bern': Shape (4, 1)\n",
      "Action 'execution_cont': Shape (4, 2)\n",
      "Action 'execution_cat': Shape (4, 2)\n",
      "\n",
      "--- Testing Evaluate Actions (Training) ---\n",
      "Total LogProb Shape: torch.Size([4, 1])\n",
      "Entropies: {'target_sel': 1.519482135772705, 'maneuver': 2.608701467514038, 'execution_bern': 0.6931433081626892, 'execution_cont': 1.0052956342697144, 'execution_cat': 0.6742390990257263}\n",
      "\n",
      "--- Verifying Layer Inputs ---\n",
      "Layer 0 (target_sel) Input Dim: 50\n",
      "Layer 1 (maneuver) Input Dim: 55\n",
      "Layer 2 (execution) Input Dim: 69\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class GeneralCascadeWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    通用自回归级联 Wrapper\n",
    "    \n",
    "    结构定义逻辑：\n",
    "    - chain_config: 一个列表，定义级联的每一层。\n",
    "    - 每一层根据上一层的输出自动扩充输入维度。\n",
    "    - 最后一层 (Tail) 可以包含并行的多个头。\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, chain_config, hidden_dims=[64, 64], device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.state_dim = state_dim\n",
    "        self.chain_config = chain_config\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_info = [] # 存储每层的元数据（类型、动作维度等）\n",
    "        \n",
    "        current_input_dim = state_dim\n",
    "        \n",
    "        print(f\"Build Cascade Actor with State Dim: {state_dim}\")\n",
    "        \n",
    "        for i, config in enumerate(chain_config):\n",
    "            layer_name = config['name']\n",
    "            layer_type = config['type']\n",
    "            \n",
    "            info = {\n",
    "                'name': layer_name,\n",
    "                'type': layer_type,\n",
    "                'input_dim': current_input_dim\n",
    "            }\n",
    "            \n",
    "            # --- 构建中间自回归层 (Regression Block) ---\n",
    "            # 这里的设定是：中间层只能是 Categorical (Cat)，用于做决策分支\n",
    "            if layer_type == 'cat':\n",
    "                action_dim = config['dim']\n",
    "                # 使用 PolicyNetDiscrete\n",
    "                net = PolicyNetDiscrete(current_input_dim, hidden_dims, action_dim)\n",
    "                self.layers.append(net)\n",
    "                \n",
    "                info['action_dim'] = action_dim\n",
    "                # 更新下一层的输入维度：State + OneHot(Action)\n",
    "                current_input_dim += action_dim \n",
    "                print(f\"  [Layer {i}] {layer_name} (Cat): In={info['input_dim']}, Out={action_dim} -> Next In={current_input_dim}\")\n",
    "                \n",
    "            # --- 构建尾部层 (Tail Block) ---\n",
    "            # 尾部不再作为下一层的输入，且可以包含混合分布\n",
    "            elif layer_type == 'tail':\n",
    "                # Tail 是一个容器，包含多个并行的头\n",
    "                tail_heads = nn.ModuleDict()\n",
    "                tail_dims = config['dims'] # dict, e.g., {'bern': 1, 'cont': 2}\n",
    "                \n",
    "                info['sub_heads'] = {}\n",
    "                \n",
    "                # 1. Tail - Bern\n",
    "                if 'bern' in tail_dims:\n",
    "                    b_dim = tail_dims['bern']\n",
    "                    tail_heads['bern'] = PolicyNetBernouli(current_input_dim, hidden_dims, b_dim)\n",
    "                    info['sub_heads']['bern'] = b_dim\n",
    "                    print(f\"  [Layer {i}] {layer_name} (Tail-Bern): In={current_input_dim}, Out={b_dim}\")\n",
    "\n",
    "                # 2. Tail - Cont\n",
    "                if 'cont' in tail_dims:\n",
    "                    c_dim = tail_dims['cont']\n",
    "                    tail_heads['cont'] = PolicyNetContinuous(current_input_dim, hidden_dims, c_dim)\n",
    "                    info['sub_heads']['cont'] = c_dim\n",
    "                    print(f\"  [Layer {i}] {layer_name} (Tail-Cont): In={current_input_dim}, Out={c_dim}\")\n",
    "\n",
    "                # 3. Tail - Cat (如果尾部也有 Cat，比如雷达模式)\n",
    "                if 'cat' in tail_dims:\n",
    "                    # 这里假设尾部的 cat 可能是 MultiDiscrete 或者 simple Discrete\n",
    "                    # 简化起见，这里假设是 list of dims (MultiDiscrete)\n",
    "                    cat_dims = tail_dims['cat'] # [3, 4]\n",
    "                    if isinstance(cat_dims, int): cat_dims = [cat_dims]\n",
    "                    \n",
    "                    # 你的 MLP_heads 里有 PolicyNetMultiDiscrete，这里也可以用\n",
    "                    # 或者复用 PolicyNetDiscrete 循环创建。这里为了演示混合头，使用 ModuleList\n",
    "                    cat_heads = nn.ModuleList()\n",
    "                    for c_dim in cat_dims:\n",
    "                        cat_heads.append(PolicyNetDiscrete(current_input_dim, hidden_dims, c_dim))\n",
    "                    tail_heads['cat'] = cat_heads\n",
    "                    info['sub_heads']['cat'] = cat_dims\n",
    "                    print(f\"  [Layer {i}] {layer_name} (Tail-Cat): In={current_input_dim}, Out={cat_dims}\")\n",
    "\n",
    "                self.layers.append(tail_heads)\n",
    "            \n",
    "            self.layer_info.append(info)\n",
    "            \n",
    "    def _to_tensor(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float, device=self.device)\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "    def get_action(self, state, explore=True):\n",
    "        \"\"\"\n",
    "        前向推理：State -> Action0 -> State+Action0 -> Action1 ...\n",
    "        \"\"\"\n",
    "        # 推荐：虽然手动detach也可以，但在推理入口加上 no_grad 是更好的习惯，能省显存\n",
    "        # 但为了保证 action_raw 里的 tensor 在某些特殊需求下（如重参数化trick）的逻辑清晰，\n",
    "        # 这里演示显式 detach 的写法。\n",
    "        \n",
    "        state = self._to_tensor(state)\n",
    "        batch_size = state.size(0)\n",
    "        \n",
    "        curr_input = state\n",
    "        \n",
    "        actions_exec = {} # 存放最终用于执行的动作（扁平化/Numpy）\n",
    "        actions_raw = {}  # 存放用于存 Buffer 的 Tensor/Index\n",
    "        \n",
    "        # 遍历每一层\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            info = self.layer_info[i]\n",
    "            name = info['name']\n",
    "            l_type = info['type']\n",
    "            \n",
    "            if l_type == 'cat':\n",
    "                # 1. 计算 Logits\n",
    "                logits = layer(curr_input, logits=True) # (B, ActionDim)\n",
    "                dist = Categorical(logits=logits)\n",
    "                \n",
    "                # 2. 采样\n",
    "                if explore:\n",
    "                    idx = dist.sample() # (B, )\n",
    "                else:\n",
    "                    idx = torch.argmax(logits, dim=-1) # (B, )\n",
    "                \n",
    "                # 3. 存储 [FIX: add .detach()]\n",
    "                # 保持维度 (B, )，Wrapper 外部可能需要 stack\n",
    "                actions_raw[name] = idx.detach().cpu().numpy() \n",
    "                actions_exec[name] = idx.detach().cpu().numpy()\n",
    "                \n",
    "                # 4. 拼接 One-Hot 到输入，供下一层使用\n",
    "                # idx: (B,) -> (B, 1)\n",
    "                # 注意：用于拼接的 one_hot 不需要 detach，因为下一层的输入需要依赖上一层的选择（如果是可导的）\n",
    "                # 但对于离散动作，索引本身阻断了梯度，所以这里 detach 与否不影响梯度流，只影响代码安全性\n",
    "                idx_view = idx.view(-1, 1)\n",
    "                one_hot = torch.zeros(batch_size, info['action_dim'], device=self.device)\n",
    "                one_hot.scatter_(1, idx_view, 1)\n",
    "                \n",
    "                curr_input = torch.cat([curr_input, one_hot], dim=-1)\n",
    "                \n",
    "            elif l_type == 'tail':\n",
    "                # Tail 层包含多个并行的头\n",
    "                heads = layer # ModuleDict\n",
    "                sub_info = info['sub_heads']\n",
    "                \n",
    "                # --- Bern ---\n",
    "                if 'bern' in heads:\n",
    "                    b_logits = heads['bern'](curr_input)\n",
    "                    dist = Bernoulli(logits=b_logits)\n",
    "                    b_val = dist.sample() if explore else (b_logits > 0).float()\n",
    "                    \n",
    "                    # [FIX: add .detach()]\n",
    "                    actions_exec[name + '_bern'] = b_val.detach().cpu().numpy()\n",
    "                    actions_raw[name + '_bern'] = b_val.detach().cpu().numpy()\n",
    "                    \n",
    "                # --- Cont ---\n",
    "                if 'cont' in heads:\n",
    "                    mu, std = heads['cont'](curr_input)\n",
    "                    dist = SquashedNormal(mu, std)\n",
    "                    if explore:\n",
    "                        a_norm, u = dist.sample()\n",
    "                    else:\n",
    "                        u = mu\n",
    "                        a_norm = torch.tanh(u)\n",
    "                    \n",
    "                    # [FIX: add .detach()]\n",
    "                    # 报错就发生在这里，因为 a_norm 和 u 都带着梯度\n",
    "                    actions_exec[name + '_cont'] = a_norm.detach().cpu().numpy()\n",
    "                    actions_raw[name + '_cont'] = u.detach().cpu().numpy() # 存 pre-tanh\n",
    "                \n",
    "                # --- Cat (Multi) ---\n",
    "                if 'cat' in heads:\n",
    "                    cat_nets = heads['cat'] # ModuleList\n",
    "                    cat_res = []\n",
    "                    for net in cat_nets:\n",
    "                        logits = net(curr_input, logits=True)\n",
    "                        dist = Categorical(logits=logits)\n",
    "                        idx = dist.sample() if explore else torch.argmax(logits, dim=-1)\n",
    "                        # [FIX: add .detach()]\n",
    "                        cat_res.append(idx.detach().cpu().numpy())\n",
    "                    \n",
    "                    # Stack results: (B, N_Heads)\n",
    "                    if len(cat_res) > 0:\n",
    "                        stacked = np.stack(cat_res, axis=-1)\n",
    "                        actions_exec[name + '_cat'] = stacked\n",
    "                        actions_raw[name + '_cat'] = stacked\n",
    "\n",
    "        return actions_exec, actions_raw\n",
    "\n",
    "    def evaluate_actions(self, state, actions_raw):\n",
    "        \"\"\"\n",
    "        训练：State + GT_Action0 -> LogProb(GT_Action1) ...\n",
    "        \"\"\"\n",
    "        state = self._to_tensor(state)\n",
    "        curr_input = state\n",
    "        \n",
    "        total_log_prob = 0\n",
    "        entropy_dict = {}\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            info = self.layer_info[i]\n",
    "            name = info['name']\n",
    "            l_type = info['type']\n",
    "            \n",
    "            if l_type == 'cat':\n",
    "                # 获取 GT 动作\n",
    "                gt_idx = torch.tensor(actions_raw[name], device=self.device).long()\n",
    "                if gt_idx.dim() > 1: gt_idx = gt_idx.squeeze(-1)\n",
    "                \n",
    "                # Forward\n",
    "                logits = layer(curr_input, logits=True)\n",
    "                dist = Categorical(logits=logits)\n",
    "                \n",
    "                # Calc LogProb & Entropy\n",
    "                log_prob = dist.log_prob(gt_idx).unsqueeze(-1) # (B, 1)\n",
    "                total_log_prob += log_prob\n",
    "                entropy_dict[name] = dist.entropy().mean().item()\n",
    "                \n",
    "                # 拼接 GT One-Hot (Teacher Forcing)\n",
    "                one_hot = F.one_hot(gt_idx, num_classes=info['action_dim']).float()\n",
    "                curr_input = torch.cat([curr_input, one_hot], dim=-1)\n",
    "                \n",
    "            elif l_type == 'tail':\n",
    "                heads = layer\n",
    "                \n",
    "                if 'bern' in heads:\n",
    "                    gt = torch.tensor(actions_raw[name + '_bern'], device=self.device).float()\n",
    "                    logits = heads['bern'](curr_input)\n",
    "                    dist = Bernoulli(logits=logits)\n",
    "                    total_log_prob += dist.log_prob(gt).sum(-1, keepdim=True)\n",
    "                    entropy_dict[name + '_bern'] = dist.entropy().mean().item()\n",
    "\n",
    "                if 'cont' in heads:\n",
    "                    gt_u = torch.tensor(actions_raw[name + '_cont'], device=self.device).float()\n",
    "                    mu, std = heads['cont'](curr_input)\n",
    "                    dist = SquashedNormal(mu, std)\n",
    "                    # SquashedNormal log_prob\n",
    "                    total_log_prob += dist.log_prob(0, gt_u).sum(-1, keepdim=True)\n",
    "                    entropy_dict[name + '_cont'] = dist.entropy().mean().item() # 近似\n",
    "                    \n",
    "                if 'cat' in heads:\n",
    "                    gt_cats = torch.tensor(actions_raw[name + '_cat'], device=self.device).long()\n",
    "                    # gt_cats: (B, N_Heads)\n",
    "                    cat_nets = heads['cat']\n",
    "                    avg_ent = 0\n",
    "                    for hi, net in enumerate(cat_nets):\n",
    "                        logits = net(curr_input, logits=True)\n",
    "                        dist = Categorical(logits=logits)\n",
    "                        gt_h = gt_cats[:, hi]\n",
    "                        total_log_prob += dist.log_prob(gt_h).unsqueeze(-1)\n",
    "                        avg_ent += dist.entropy().mean().item()\n",
    "                    entropy_dict[name + '_cat'] = avg_ent / len(cat_nets)\n",
    "\n",
    "        return total_log_prob, entropy_dict\n",
    "\n",
    "# ==========================================\n",
    "# 测试代码\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 定义结构\n",
    "    # 场景：先选目标(5个)，再选机动(14种)，最后决定开火(1个开关)和舵偏(2维)\n",
    "    config = [\n",
    "        # Layer 0: 自回归块 1 (目标选择)\n",
    "        {'name': 'target_sel', 'type': 'cat', 'dim': 5}, \n",
    "        \n",
    "        # Layer 1: 自回归块 2 (机动选择，依赖目标)\n",
    "        {'name': 'maneuver',   'type': 'cat', 'dim': 14},\n",
    "        \n",
    "        # Layer 2: 尾部 (依赖目标 + 机动)\n",
    "        {'name': 'execution',  'type': 'tail', 'dims': {\n",
    "            'bern': 1,      # 开火\n",
    "            'cont': 2,      # 舵偏\n",
    "            'cat': [2, 2]   # 雷达开关，干扰开关 (MultiDiscrete)\n",
    "        }}\n",
    "    ]\n",
    "    \n",
    "    # 2. 初始化 Wrapper\n",
    "    state_dim = 50\n",
    "    actor = GeneralCascadeWrapper(state_dim, config, hidden_dims=[32])\n",
    "    print(\"\\n--- Network Constructed ---\")\n",
    "    \n",
    "    # 3. 模拟 Batch 数据\n",
    "    batch_size = 4\n",
    "    dummy_state = torch.randn(batch_size, state_dim)\n",
    "    \n",
    "    # 4. 测试 Get Action (推理)\n",
    "    print(\"\\n--- Testing Get Action (Inference) ---\")\n",
    "    actions_exec, actions_raw = actor.get_action(dummy_state, explore=True)\n",
    "    \n",
    "    for k, v in actions_exec.items():\n",
    "        print(f\"Action '{k}': Shape {v.shape}\")\n",
    "        # print(v)\n",
    "\n",
    "    # 5. 测试 Evaluate Actions (训练)\n",
    "    print(\"\\n--- Testing Evaluate Actions (Training) ---\")\n",
    "    log_probs, entropies = actor.evaluate_actions(dummy_state, actions_raw)\n",
    "    \n",
    "    print(f\"Total LogProb Shape: {log_probs.shape}\") # Should be (B, 1)\n",
    "    print(\"Entropies:\", entropies)\n",
    "    \n",
    "    # 6. 验证维度拼接逻辑\n",
    "    # 理论输入维度：\n",
    "    # L0 In: 50\n",
    "    # L1 In: 50 + 5 = 55\n",
    "    # L2 In: 55 + 14 = 69\n",
    "    print(\"\\n--- Verifying Layer Inputs ---\")\n",
    "    # 这里通过打印 layer_info 来验证\n",
    "    for i, info in enumerate(actor.layer_info):\n",
    "        print(f\"Layer {i} ({info['name']}) Input Dim: {info['input_dim']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
